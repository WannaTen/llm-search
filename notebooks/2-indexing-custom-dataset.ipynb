{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing custom data with LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snexus/.cache/pypoetry/virtualenvs/llmplay-MNp-VQJi-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.llms.base import LLM\n",
    "from llama_index import  SimpleDirectoryReader, LangchainEmbedding, GPTListIndex, PromptHelper, GPTSimpleVectorIndex, GPTListIndex\n",
    "from llama_index import LLMPredictor, ServiceContext\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from transformers import pipeline\n",
    "from typing import Optional, List, Mapping, Any\n",
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt helper\n",
    "# set maximum input size\n",
    "max_input_size = 2048\n",
    "# set number of output tokens\n",
    "num_output = 256\n",
    "# set maximum chunk overlap\n",
    "max_chunk_overlap = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"databricks/dolly-v2-2-8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = pipeline(model=model_name, \n",
    "                         torch_dtype=torch.bfloat16, \n",
    "                         trust_remote_code=True,\n",
    "                         device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://gpt-index.readthedocs.io/en/latest/how_to/customization/custom_llms.html\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    model_name = model_name\n",
    "    \n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        response = model_pipeline(prompt)\n",
    "        return response\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"name_of_model\": self.model_name}\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_predictor = LLMPredictor(llm=CustomLLM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser(text_splitter=TokenTextSplitter(chunk_size=512, chunk_overlap=max_chunk_overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model,\n",
    "                                               prompt_helper=prompt_helper, node_parser=node_parser, chunk_size_limit=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this for plain text data\n",
    "# documents = SimpleDirectoryReader('../sample_data').load_data(concatenate=True\n",
    "# len(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a single markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "from pathlib import Path\n",
    "\n",
    "MarkdownReader = download_loader(\"MarkdownReader\")\n",
    "\n",
    "loader = MarkdownReader()\n",
    "documents = loader.load_data(file=Path('../sample_data/all-weather-leveraged-portfolio.md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 177.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 189.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.64it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 3910 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex.from_documents(documents, \n",
    "                                            service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 161.73it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 284 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"What is the best portfolio for a long term investor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is based on the diversification principle and the perception of volatility for any specific asset class. If you invest across all asset classes, you are reducing your portfolio exposure to any one particular asset class and increase your exposure to others. Based on the objective of minimizing risk and volatility of overall portfolio, a diversified portfolio of 30% stocks, 40% treasuries, 15% intermediate-term treasuries, 7.5% commodities, and 7.5% gold is the best approach.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 157.85it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 422 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"What is the best portfolio for a short term investor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value, Deep Value, Growth At A Reasonable Price, Long Only\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 146.24it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 453 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"Which portolio provides best risk adjusted returns?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general answer is there is no best portfolio as it depends on a person's risk appetite, time horizon and other factors. For the purpose of this article,  I will use VTI TQQQ as an example.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "from pathlib import Path\n",
    "\n",
    "PDFReader = download_loader(\"PDFReader\")\n",
    "\n",
    "loader = PDFReader()\n",
    "documents = loader.load_data(file=Path('../sample_data/ato-dividends.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.87it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.75it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.59it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.76it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 178.88it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 19305 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 183.22it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 569 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"Write a short summary on how dividends are taxed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividends are taxed as a form of Income, depending on whether they are paid as money or other property. If they are paid as money, tax is paid at income tax rates. If they are paid other property, such as shares, tax is paid at capital gains tax rates. The company should issue you with a statement showing the market value of the shares at the time of reinvestment. You will then need to work out any potential capital gains tax from the eventual disposal of the shares.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.70it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 504 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"Summarize a difference between dividend and distribution in 1 sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividend and distribution are different in that distribution is a payment to a\n",
      "shareholder from the company for account of the company and is taxed at lower\n",
      "rates than dividends.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 175.18it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 627 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 14 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"In no more than 5 sentences, how franked dividends are taxed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In no more than 5 sentences, how franked dividends are taxed?\n",
      "A resident company, or a New Zealand franking company that has elected to join\n",
      "the Australian imputation system, may pay or credit you with a franked dividend.\n",
      "Dividends can be fully franked (meaning that the whole amount of the dividend\n",
      "carries a franking credit) or partly franked (meaning that the dividend has a franked\n",
      "amount and an unfranked amount). The dividend statement you receive from the company\n",
      "paying the franked dividend must state the amount\n",
      "given the context information and not prior knowledge, answer the question: In no more than 5 sentences, how franked dividends are taxed?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 155.68it/s]\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 508 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 12 tokens\n"
     ]
    }
   ],
   "source": [
    "result = index.query(\"What is a difference between franked and unfranked dividends?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A franked dividend is any dividend that is subject to a tax offset in the form of a\n",
      "franking credit.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmplay-Mz0nj96j-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
