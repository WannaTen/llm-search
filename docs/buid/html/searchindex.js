Search.setIndex({"docnames": ["configure_doc", "configure_model", "index", "installation", "usage"], "filenames": ["configure_doc.rst", "configure_model.rst", "index.rst", "installation.rst", "usage.rst"], "titles": ["Documents and Embedding Config", "LLM Model Config", "Welcome to llmsearch\u2019s documentation!", "Prerequisites", "Create embeddings"], "terms": {"cache_fold": [0, 1], "path": [0, 1, 4], "cach": [0, 1], "folder": [0, 1, 2, 4], "specifi": [0, 4], "model": [0, 2, 3, 4], "huggingfac": [0, 2], "sentenc": [0, 2], "transform": [0, 2], "attent": [0, 2], "embedding_path": 0, "should": 0, "uniqu": 0, "per": 0, "file": [0, 1, 2, 3, 4], "embeddings_path": 0, "where": [0, 2], "save": [0, 2], "embedding_model": [0, 4], "option": [0, 2], "specif": [0, 2], "default": [0, 1, 4], "i": [0, 1, 2, 3, 4], "e5": [0, 2, 4], "larg": [0, 2, 4], "v2": [0, 4], "swap": 0, "smaller": 0, "out": 0, "cuda": [0, 3], "memori": 0, "type": [0, 1], "sentence_transform": 0, "other": [0, 2, 4], "support": [0, 2, 4], "instruct": [0, 1], "model_nam": [0, 1], "infloat": 0, "splade_config": 0, "batch": 0, "size": 0, "spars": [0, 2, 4], "reduc": 0, "get": 0, "error": 0, "n_batch": [0, 1], "5": [0, 1, 2], "chunk_siz": 0, "one": [0, 4], "more": [0, 2, 4], "chunk": 0, "split": 0, "queri": [0, 2], "multi": [0, 2], "result": [0, 2], "slower": 0, "1024": 0, "document_set": 0, "can": [0, 2, 4], "multipl": [0, 2], "collect": [0, 2], "filter": [0, 2], "label": 0, "doc_path": 0, "doc": 0, "exclude_path": 0, "exclud": 0, "subfolder1": 0, "subfolder2": 0, "scan_extens": 0, "extens": 0, "scan": [0, 4], "recurs": 0, "pdf": [0, 2], "md": [0, 2], "additional_parser_set": 0, "section": [0, 1, 2, 4], "don": [0, 1], "t": [0, 1, 2], "have": 0, "includ": [0, 2, 3], "skip_first": 0, "true": [0, 1], "skip": 0, "first": 0, "which": [0, 4], "often": 0, "contain": [0, 1, 3], "metadata": [0, 2], "merge_sect": 0, "fals": [0, 1], "merg": 0, "head": [0, 2], "possibl": 0, "turn": [0, 2], "off": 0, "depend": [0, 2], "stuctur": 0, "remove_imag": 0, "remov": 0, "imag": [0, 2], "link": [0, 2], "passage_prefix": 0, "passag": 0, "prefix": 0, "need": [0, 2, 4], "sourc": [0, 3], "text": 0, "work": [0, 2], "properli": 0, "docum": 0, "1": [0, 1], "add": 0, "current": 0, "anoth": 0, "2": [0, 1], "semantic_search": 0, "search_typ": 0, "similar": 0, "onli": [0, 1], "replace_output_path": 0, "list": [0, 2], "search": [0, 2, 3, 4], "replac": [0, 2], "set": [0, 3], "substring_search": 0, "storag": [0, 1], "llm": [0, 2, 3, 4], "substr": 0, "output": [0, 2], "substring_replac": 0, "obsidian": 0, "open": [0, 4], "vault": 0, "knowledg": [0, 1], "base": [0, 1, 2, 4], "thi": [0, 1, 2, 4], "string": [0, 1], "append_suffix": 0, "addit": [0, 2, 4], "templat": [0, 1, 3], "append": 0, "an": [0, 1, 2, 4], "us": [0, 1, 2, 4], "deep": [0, 2], "append_templ": 0, "page": [0, 2], "For": [0, 1, 3], "from": [0, 2, 4], "parser": [0, 2], "Will": 0, "ensur": 0, "context": [0, 1, 4], "provid": [0, 1, 3], "less": 0, "than": 0, "max_char_s": 0, "local": [0, 2, 3], "host": [0, 2, 3], "limit": 0, "hardwar": 0, "4096": 0, "query_prefix": 0, "hyde": [0, 2], "enabl": [0, 2], "multiqueri": 0, "rerank": [0, 2], "bge": [0, 2], "baai": 0, "marco": [0, 2], "cross": [0, 2], "encod": [0, 2], "m": [0, 2, 3, 4], "minilm": [0, 2], "l": 0, "6": 0, "persist_response_db_path": 0, "respons": [0, 1, 2], "db": 0, "sqlite": 0, "databas": [0, 2, 4], "filenam": 0, "allow": [0, 2, 4], "offlien": 0, "futur": [0, 2], "analysi": [0, 2], "pydant": [0, 1], "llmsearch": [0, 1, 4], "show": [0, 1], "json": [0, 1], "schema": [0, 1], "titl": [0, 1], "object": [0, 1], "properti": [0, 1], "format": [0, 1, 2], "ref": 0, "def": 0, "embeddingsconfig": [0, 2], "semanticsearchconfig": [0, 2], "anyof": [0, 1], "llmconfig": 0, "null": [0, 1], "persist": 0, "documentpathset": [0, 2], "directori": [0, 3], "item": 0, "arrai": 0, "requir": [0, 1, 2, 3], "embedddingsspladeconfig": [0, 2], "3": [0, 1, 2, 3], "n": 0, "integ": 0, "embeddingmodel": [0, 2], "embeddingmodeltyp": [0, 2], "name": [0, 1], "additional_kwarg": 0, "kwarg": [0, 1], "enum": 0, "additionalproperti": 0, "allof": 0, "hkunlp": 0, "instructor": [0, 2], "hydeset": [0, 2], "boolean": [0, 1], "hyde_prompt": 0, "write": 0, "short": 0, "answer": [0, 1, 2], "question": [0, 1, 2], "prompt": [0, 1], "param": [0, 1], "multiqueryset": [0, 2], "multiquery_prompt": 0, "you": [0, 1, 4], "ar": [0, 2, 4], "help": 0, "assist": 0, "gener": [0, 2, 3, 4], "n_version": 0, "relat": 0, "suggest": 0, "without": [0, 2, 4], "compound": 0, "varieti": 0, "cover": 0, "differ": [0, 2], "aspect": 0, "topic": [0, 2], "make": [0, 1, 2], "sure": [0, 2], "thei": 0, "complet": 0, "origin": [0, 2], "separ": 0, "newlin": 0, "shouldn": 0, "enumer": 0, "version": [0, 1, 3], "obsidianadvanceduri": [0, 2], "append_heading_templ": 0, "replaceoutputpath": [0, 2], "rerankermodel": [0, 2], "rerankerset": [0, 2], "mmr": 0, "obsidian_advanced_uri": 0, "suffixappend": 0, "max_k": 0, "15": [0, 1], "max": 0, "k": 0, "2048": 0, "char": 0, "field": [0, 1], "pathlib": [0, 1], "none": [0, 1], "str": [0, 1], "directli": 0, "confgur": 0, "semant": [0, 2], "check_embeddings_exist": 0, "bool": [0, 1], "check": 0, "exist": [0, 4], "interfac": [0, 2, 4], "interact": [0, 2, 3], "descript": [0, 2], "page_cont": 0, "content": 0, "dict": [0, 1], "ani": [0, 1], "defin": 0, "given": [0, 1, 2], "int": 0, "class": 0, "valu": 0, "modul": [0, 2], "qualnam": 0, "start": 0, "boundari": 0, "dens": [0, 2, 4], "splade": [0, 2, 4], "return": 0, "bge_rerank": 0, "responsemodel": [0, 2], "id": 0, "uuid": 0, "average_scor": 0, "averag": 0, "score": 0, "number": 0, "semanticsearchoutput": [0, 2], "hyde_respons": 0, "chunk_link": 0, "chunk_text": 0, "float": 0, "liter": 0, "suffix": 0, "url": [0, 3], "extern": 0, "applic": [0, 2], "e": [0, 2, 3], "g": [0, 2], "maximum": 0, "charact": 0, "fit": 0, "window": 0, "retriev": [0, 2], "OR": [0, 2], "both": [0, 4], "befor": [0, 2], "re": [0, 2, 4], "ranker": [0, 4], "creat": [1, 2, 3], "env": [1, 3], "api": [1, 2, 3], "kei": [1, 3], "relev": 1, "entir": [1, 2], "prompt_templ": 1, "contex": 1, "inform": [1, 4], "below": 1, "prior": 1, "detail": 1, "If": 1, "isn": 1, "sai": 1, "know": 1, "model_kwarg": 1, "temperatur": 1, "0": 1, "gpt": 1, "turbo": 1, "model_path": 1, "airoboro": 1, "l2": 1, "13b": 1, "gpt4": 1, "4": [1, 2, 3], "q4_k_m": 1, "gguf": 1, "follow": [1, 2, 4], "piec": 1, "end": 1, "try": 1, "up": 1, "model_init_param": 1, "n_ctx": 1, "1512": 1, "512": 1, "n_gpu_lay": 1, "25": 1, "max_token": 1, "top_p": 1, "top_k": 1, "40": 1, "api_kei": 1, "base_url": 1, "http": [1, 2, 3], "8000": 1, "microsoft": 1, "phi": 1, "tiiuae": 1, "falcon": 1, "7b": 1, "load_8bit": 1, "trust_remote_cod": 1, "devic": 1, "auto": 1, "pipeline_kwarg": 1, "do_sampl": 1, "max_new_token": 1, "num_return_sequ": 1, "01": 1, "azureopenaimodelconfig": [1, 2], "deployment_nam": 1, "deploy": 1, "openai_api_typ": 1, "azur": [1, 2], "openai_api_vers": 1, "2023": 1, "05": 1, "openai_api_bas": 1, "huggingfacemodelconfig": [1, 2], "tokenizer_nam": 1, "token": 1, "load": 1, "8bit": 1, "trust": 1, "remot": 1, "code": [1, 2], "tokenzier_kwarg": 1, "tokenzi": 1, "pipelin": 1, "llamamodelconfig": [1, 2], "init": 1, "openaimodelconfig": [1, 2], "The": [2, 4], "purpos": 2, "packag": [2, 3], "offer": 2, "conveni": 2, "system": 2, "simpl": 2, "yaml": [2, 4], "special": 2, "improv": 2, "variou": 2, "compon": 2, "better": 2, "pars": [2, 3], "hybrid": 2, "rank": [2, 4], "abil": 2, "custom": 2, "embed": [2, 3], "design": 2, "languag": 2, "whether": 2, "openai": [2, 3], "build": 2, "divid": 2, "logic": 2, "subhead": 2, "block": 2, "like": 2, "clean": 2, "ad": [2, 4], "mupdf": 2, "docx": 2, "nest": 2, "common": 2, "unstructur": 2, "pre": 2, "processor": 2, "io": 2, "github": [2, 3], "core": 2, "partit": 2, "html": [2, 3], "updat": 2, "increment": [2, 4], "index": [2, 3, 4], "store": 2, "them": [2, 4], "vector": [2, 4], "chromadb": [2, 4], "multilingu": 2, "com": [2, 3], "naver": 2, "strategi": 2, "see": 2, "www": 2, "sbert": 2, "net": 2, "exampl": 2, "retrieve_rerank": 2, "readm": 2, "besid": 2, "modern": 2, "hypothet": 2, "arxiv": 2, "org": [2, 3], "2212": 2, "10496": 2, "warn": 2, "via": 2, "config": [2, 4], "webapp": [2, 4], "significantli": 2, "alter": 2, "qualiti": 2, "pleas": 2, "read": 2, "paper": 2, "empir": 2, "observ": 2, "boost": 2, "user": 2, "formul": 2, "quesiton": 2, "domain": 2, "when": [2, 4], "learn": 2, "new": [2, 3, 4], "inspir": 2, "rag": 2, "fusion": 2, "towardsdatasci": 2, "forget": 2, "1147298d8ad1": 2, "either": 2, "variant": 2, "same": 2, "bridg": 2, "gap": 2, "terminologi": 2, "angl": 2, "perspect": 2, "accord": 2, "articl": 2, "intern": 2, "method": 2, "chatgpt": 2, "llama": [2, 3], "cpp": [2, 3], "full": 2, "ggerganov": 2, "autogptq": 2, "temporarili": 2, "disabl": 2, "due": 2, "broken": 2, "interoper": 2, "litellm": 2, "ollama": 2, "hundr": 2, "sample_templ": 2, "web": [2, 4], "jump": 2, "individu": 2, "header": 2, "markdown": 2, "offlin": [2, 4], "experiment": 2, "prerequisit": 2, "virtualenv": 2, "two": 2, "refer": 2, "llamacpp": 2, "test": 3, "ubuntu": 3, "22": 3, "04": 3, "opensus": 3, "tumblewe": 3, "nvidia": 3, "gpu": 3, "usag": 3, "python": 3, "10": 3, "11": 3, "dev": 3, "python3": 3, "toolkit": 3, "8": 3, "12": 3, "develop": 3, "To": [3, 4], "root": 3, "repositori": 3, "A": 3, "env_templ": 3, "epub": 3, "document": 3, "pandoc": 3, "git": 3, "clone": 3, "snexu": 3, "cd": 3, "environ": [3, 4], "venv": 3, "activ": 3, "bin": 3, "variabl": [3, 4], "compil": 3, "assum": 3, "point": [3, 4], "usr": 3, "setvar": 3, "sh": 3, "newest": 3, "stabl": 3, "torch": 3, "x": 3, "pip3": 3, "torchvis": 3, "download": 3, "pytorch": 3, "whl": 3, "cu118": 3, "pip": 3, "step": 4, "command": 4, "line": 4, "run": 4, "c": 4, "unless": 4, "otherwis": 4, "abov": 4, "known": 4, "its": 4, "high": 4, "perform": 4, "find": 4, "about": 4, "mteb": 4, "leadboard": 4, "In": 4, "algorithm": 4, "chang": 4, "execut": 4, "detect": 4, "md5": 4, "hash": 4, "rescan": 4, "scratch": 4, "launch": 4, "config_fold": 4, "model_config": 4, "here": 4, "tool": 4, "switch": 4, "between": 4, "suppli": 4, "fastapi_llm_config": 4, "llmsearchapi": 4}, "objects": {"llmsearch": [[0, 0, 0, "-", "config"]], "llmsearch.config": [[0, 1, 1, "", "Config"], [0, 1, 1, "", "Document"], [0, 1, 1, "", "DocumentPathSettings"], [0, 1, 1, "", "EmbedddingsSpladeConfig"], [0, 1, 1, "", "EmbeddingModel"], [0, 4, 1, "", "EmbeddingModelType"], [0, 1, 1, "", "EmbeddingsConfig"], [0, 1, 1, "", "HydeSettings"], [0, 1, 1, "", "MultiQuerySettings"], [0, 1, 1, "", "ObsidianAdvancedURI"], [0, 1, 1, "", "ReplaceOutputPath"], [0, 4, 1, "", "RerankerModel"], [0, 1, 1, "", "RerankerSettings"], [0, 1, 1, "", "ResponseModel"], [0, 1, 1, "", "SemanticSearchConfig"], [0, 1, 1, "", "SemanticSearchOutput"]], "llmsearch.config.Config": [[0, 2, 1, "", "cache_folder"], [0, 3, 1, "", "check_embeddings_exist"], [0, 2, 1, "", "embeddings"], [0, 2, 1, "", "llm"], [0, 2, 1, "", "persist_response_db_path"], [0, 2, 1, "", "semantic_search"]], "llmsearch.config.Document": [[0, 2, 1, "", "metadata"], [0, 2, 1, "", "page_content"]], "llmsearch.config.DocumentPathSettings": [[0, 2, 1, "", "additional_parser_settings"], [0, 2, 1, "", "doc_path"], [0, 2, 1, "", "exclude_paths"], [0, 2, 1, "", "label"], [0, 2, 1, "", "passage_prefix"], [0, 2, 1, "", "scan_extensions"]], "llmsearch.config.EmbedddingsSpladeConfig": [[0, 2, 1, "", "n_batch"]], "llmsearch.config.EmbeddingModel": [[0, 2, 1, "", "additional_kwargs"], [0, 2, 1, "", "model_name"], [0, 2, 1, "", "type"]], "llmsearch.config.EmbeddingsConfig": [[0, 2, 1, "", "chunk_sizes"], [0, 2, 1, "", "document_settings"], [0, 2, 1, "", "embedding_model"], [0, 2, 1, "", "embeddings_path"], [0, 5, 1, "", "labels"], [0, 2, 1, "", "splade_config"]], "llmsearch.config.HydeSettings": [[0, 2, 1, "", "enabled"], [0, 2, 1, "", "hyde_prompt"]], "llmsearch.config.MultiQuerySettings": [[0, 2, 1, "", "enabled"], [0, 2, 1, "", "multiquery_prompt"], [0, 2, 1, "", "n_versions"]], "llmsearch.config.ObsidianAdvancedURI": [[0, 2, 1, "", "append_heading_template"]], "llmsearch.config.ReplaceOutputPath": [[0, 2, 1, "", "substring_replace"], [0, 2, 1, "", "substring_search"]], "llmsearch.config.RerankerSettings": [[0, 2, 1, "", "enabled"], [0, 2, 1, "", "model"]], "llmsearch.config.ResponseModel": [[0, 2, 1, "", "average_score"], [0, 2, 1, "", "hyde_response"], [0, 2, 1, "", "id"], [0, 2, 1, "", "question"], [0, 2, 1, "", "response"], [0, 2, 1, "", "semantic_search"]], "llmsearch.config.SemanticSearchConfig": [[0, 2, 1, "", "append_suffix"], [0, 2, 1, "", "hyde"], [0, 2, 1, "", "max_char_size"], [0, 2, 1, "", "max_k"], [0, 2, 1, "", "multiquery"], [0, 2, 1, "", "obsidian_advanced_uri"], [0, 2, 1, "", "query_prefix"], [0, 2, 1, "", "replace_output_path"], [0, 2, 1, "", "reranker"], [0, 2, 1, "", "search_type"]], "llmsearch.config.SemanticSearchOutput": [[0, 2, 1, "", "chunk_link"], [0, 2, 1, "", "chunk_text"], [0, 2, 1, "", "metadata"]], "llmsearch.models": [[1, 0, 0, "-", "config"]], "llmsearch.models.config": [[1, 1, 1, "", "AzureOpenAIModelConfig"], [1, 1, 1, "", "HuggingFaceModelConfig"], [1, 1, 1, "", "LlamaModelConfig"], [1, 1, 1, "", "OpenAIModelConfig"]], "llmsearch.models.config.AzureOpenAIModelConfig": [[1, 2, 1, "", "deployment_name"], [1, 2, 1, "", "model_kwargs"], [1, 2, 1, "", "model_name"], [1, 2, 1, "", "openai_api_base"], [1, 2, 1, "", "openai_api_type"], [1, 2, 1, "", "openai_api_version"], [1, 2, 1, "", "prompt_template"]], "llmsearch.models.config.HuggingFaceModelConfig": [[1, 2, 1, "", "cache_folder"], [1, 2, 1, "", "load_8bit"], [1, 2, 1, "", "model_kwargs"], [1, 2, 1, "", "model_name"], [1, 2, 1, "", "pipeline_kwargs"], [1, 2, 1, "", "prompt_template"], [1, 2, 1, "", "tokenizer_name"], [1, 2, 1, "", "tokenzier_kwargs"], [1, 2, 1, "", "trust_remote_code"]], "llmsearch.models.config.LlamaModelConfig": [[1, 2, 1, "", "model_init_params"], [1, 2, 1, "", "model_kwargs"], [1, 2, 1, "", "model_path"], [1, 2, 1, "", "prompt_template"]], "llmsearch.models.config.OpenAIModelConfig": [[1, 2, 1, "", "model_kwargs"], [1, 2, 1, "", "prompt_template"]]}, "objtypes": {"0": "py:module", "1": "py:pydantic_model", "2": "py:pydantic_field", "3": "py:method", "4": "py:class", "5": "py:property"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "pydantic_model", "Python model"], "2": ["py", "pydantic_field", "Python field"], "3": ["py", "method", "Python method"], "4": ["py", "class", "Python class"], "5": ["py", "property", "Python property"]}, "titleterms": {"document": [0, 2, 4], "embed": [0, 4], "config": [0, 1], "configur": [0, 1, 2], "exampl": [0, 1], "refer": [0, 1], "llm": 1, "model": 1, "openai": 1, "llamacpp": 1, "ollama": 1, "litellm": 1, "huggingfac": 1, "welcom": 2, "llmsearch": 2, "": 2, "featur": 2, "instal": [2, 3], "usag": 2, "indic": 2, "tabl": 2, "prerequisit": 3, "virtualenv": 3, "base": 3, "creat": 4, "updat": 4, "option": 4, "interact": 4, "api": 4, "experiment": 4}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Documents and Embedding Config": [[0, "documents-and-embedding-config"]], "Configuration example": [[0, "configuration-example"]], "Document Config Reference": [[0, "document-config-reference"]], "LLM Model Config": [[1, "llm-model-config"]], "Configuration examples": [[1, "configuration-examples"]], "OpenAI": [[1, "openai"]], "llamacpp": [[1, "llamacpp"]], "Ollama + Litellm": [[1, "ollama-litellm"]], "Huggingface": [[1, "huggingface"]], "Reference": [[1, "module-llmsearch.models.config"]], "Welcome to llmsearch\u2019s documentation!": [[2, "welcome-to-llmsearch-s-documentation"]], "Features": [[2, "features"]], "Installation": [[2, "installation"]], "Configuration": [[2, "configuration"]], "Usage": [[2, "usage"]], "Indices and tables": [[2, "indices-and-tables"]], "Prerequisites": [[3, "prerequisites"]], "Virtualenv based installation": [[3, "virtualenv-based-installation"]], "Create embeddings": [[4, "create-embeddings"]], "Update embeddings (optional)": [[4, "update-embeddings-optional"]], "Interact with documents": [[4, "interact-with-documents"]], "API (Experimental)": [[4, "api-experimental"]]}, "indexentries": {"embeddingmodeltype (class in llmsearch.config)": [[0, "llmsearch.config.EmbeddingModelType"]], "rerankermodel (class in llmsearch.config)": [[0, "llmsearch.config.RerankerModel"]], "additional_kwargs (llmsearch.config.embeddingmodel attribute)": [[0, "llmsearch.config.EmbeddingModel.additional_kwargs"]], "additional_parser_settings (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.additional_parser_settings"]], "append_heading_template (llmsearch.config.obsidianadvanceduri attribute)": [[0, "llmsearch.config.ObsidianAdvancedURI.append_heading_template"]], "append_suffix (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.append_suffix"]], "average_score (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.average_score"]], "cache_folder (llmsearch.config.config attribute)": [[0, "llmsearch.config.Config.cache_folder"]], "check_embeddings_exist() (llmsearch.config.config method)": [[0, "llmsearch.config.Config.check_embeddings_exist"]], "chunk_link (llmsearch.config.semanticsearchoutput attribute)": [[0, "llmsearch.config.SemanticSearchOutput.chunk_link"]], "chunk_sizes (llmsearch.config.embeddingsconfig attribute)": [[0, "llmsearch.config.EmbeddingsConfig.chunk_sizes"]], "chunk_text (llmsearch.config.semanticsearchoutput attribute)": [[0, "llmsearch.config.SemanticSearchOutput.chunk_text"]], "doc_path (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.doc_path"]], "document_settings (llmsearch.config.embeddingsconfig attribute)": [[0, "llmsearch.config.EmbeddingsConfig.document_settings"]], "embedding_model (llmsearch.config.embeddingsconfig attribute)": [[0, "llmsearch.config.EmbeddingsConfig.embedding_model"]], "embeddings (llmsearch.config.config attribute)": [[0, "llmsearch.config.Config.embeddings"]], "embeddings_path (llmsearch.config.embeddingsconfig attribute)": [[0, "llmsearch.config.EmbeddingsConfig.embeddings_path"]], "enabled (llmsearch.config.hydesettings attribute)": [[0, "llmsearch.config.HydeSettings.enabled"]], "enabled (llmsearch.config.multiquerysettings attribute)": [[0, "llmsearch.config.MultiQuerySettings.enabled"]], "enabled (llmsearch.config.rerankersettings attribute)": [[0, "llmsearch.config.RerankerSettings.enabled"]], "exclude_paths (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.exclude_paths"]], "hyde (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.hyde"]], "hyde_prompt (llmsearch.config.hydesettings attribute)": [[0, "llmsearch.config.HydeSettings.hyde_prompt"]], "hyde_response (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.hyde_response"]], "id (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.id"]], "label (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.label"]], "labels (llmsearch.config.embeddingsconfig property)": [[0, "llmsearch.config.EmbeddingsConfig.labels"]], "llm (llmsearch.config.config attribute)": [[0, "llmsearch.config.Config.llm"]], "llmsearch.config": [[0, "module-llmsearch.config"]], "max_char_size (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.max_char_size"]], "max_k (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.max_k"]], "metadata (llmsearch.config.document attribute)": [[0, "llmsearch.config.Document.metadata"]], "metadata (llmsearch.config.semanticsearchoutput attribute)": [[0, "llmsearch.config.SemanticSearchOutput.metadata"]], "model (llmsearch.config.rerankersettings attribute)": [[0, "llmsearch.config.RerankerSettings.model"]], "model_name (llmsearch.config.embeddingmodel attribute)": [[0, "llmsearch.config.EmbeddingModel.model_name"]], "module": [[0, "module-llmsearch.config"], [1, "module-llmsearch.models.config"]], "multiquery (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.multiquery"]], "multiquery_prompt (llmsearch.config.multiquerysettings attribute)": [[0, "llmsearch.config.MultiQuerySettings.multiquery_prompt"]], "n_batch (llmsearch.config.embedddingsspladeconfig attribute)": [[0, "llmsearch.config.EmbedddingsSpladeConfig.n_batch"]], "n_versions (llmsearch.config.multiquerysettings attribute)": [[0, "llmsearch.config.MultiQuerySettings.n_versions"]], "obsidian_advanced_uri (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.obsidian_advanced_uri"]], "page_content (llmsearch.config.document attribute)": [[0, "llmsearch.config.Document.page_content"]], "passage_prefix (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.passage_prefix"]], "persist_response_db_path (llmsearch.config.config attribute)": [[0, "llmsearch.config.Config.persist_response_db_path"]], "query_prefix (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.query_prefix"]], "question (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.question"]], "replace_output_path (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.replace_output_path"]], "reranker (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.reranker"]], "response (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.response"]], "scan_extensions (llmsearch.config.documentpathsettings attribute)": [[0, "llmsearch.config.DocumentPathSettings.scan_extensions"]], "search_type (llmsearch.config.semanticsearchconfig attribute)": [[0, "llmsearch.config.SemanticSearchConfig.search_type"]], "semantic_search (llmsearch.config.config attribute)": [[0, "llmsearch.config.Config.semantic_search"]], "semantic_search (llmsearch.config.responsemodel attribute)": [[0, "llmsearch.config.ResponseModel.semantic_search"]], "splade_config (llmsearch.config.embeddingsconfig attribute)": [[0, "llmsearch.config.EmbeddingsConfig.splade_config"]], "substring_replace (llmsearch.config.replaceoutputpath attribute)": [[0, "llmsearch.config.ReplaceOutputPath.substring_replace"]], "substring_search (llmsearch.config.replaceoutputpath attribute)": [[0, "llmsearch.config.ReplaceOutputPath.substring_search"]], "type (llmsearch.config.embeddingmodel attribute)": [[0, "llmsearch.config.EmbeddingModel.type"]], "cache_folder (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.cache_folder"]], "deployment_name (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.deployment_name"]], "llmsearch.models.config": [[1, "module-llmsearch.models.config"]], "load_8bit (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.load_8bit"]], "model_init_params (llmsearch.models.config.llamamodelconfig attribute)": [[1, "llmsearch.models.config.LlamaModelConfig.model_init_params"]], "model_kwargs (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.model_kwargs"]], "model_kwargs (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.model_kwargs"]], "model_kwargs (llmsearch.models.config.llamamodelconfig attribute)": [[1, "llmsearch.models.config.LlamaModelConfig.model_kwargs"]], "model_kwargs (llmsearch.models.config.openaimodelconfig attribute)": [[1, "llmsearch.models.config.OpenAIModelConfig.model_kwargs"]], "model_name (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.model_name"]], "model_name (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.model_name"]], "model_path (llmsearch.models.config.llamamodelconfig attribute)": [[1, "llmsearch.models.config.LlamaModelConfig.model_path"]], "openai_api_base (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.openai_api_base"]], "openai_api_type (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.openai_api_type"]], "openai_api_version (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.openai_api_version"]], "pipeline_kwargs (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.pipeline_kwargs"]], "prompt_template (llmsearch.models.config.azureopenaimodelconfig attribute)": [[1, "llmsearch.models.config.AzureOpenAIModelConfig.prompt_template"]], "prompt_template (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.prompt_template"]], "prompt_template (llmsearch.models.config.llamamodelconfig attribute)": [[1, "llmsearch.models.config.LlamaModelConfig.prompt_template"]], "prompt_template (llmsearch.models.config.openaimodelconfig attribute)": [[1, "llmsearch.models.config.OpenAIModelConfig.prompt_template"]], "tokenizer_name (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.tokenizer_name"]], "tokenzier_kwargs (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.tokenzier_kwargs"]], "trust_remote_code (llmsearch.models.config.huggingfacemodelconfig attribute)": [[1, "llmsearch.models.config.HuggingFaceModelConfig.trust_remote_code"]]}})